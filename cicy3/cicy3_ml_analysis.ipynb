{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CFEPJ7w9YT0W"
   },
   "source": [
    "# CICY 3-folds: ML analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Author: [Harold Erbin](mailto:erbin@mit.edu)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the notebook for the analysis done in [arxiv:2007.13379](https://arxiv.org/abs/2007.13379) and [arxiv:2007.15706](https://arxiv.org/abs/2007.15706).\n",
    "\n",
    "Data is automatically downloaded in the current folder. It has been converted to HDF from the original data (see [cicy3f.README](http://www.lpthe.jussieu.fr/~erbin/files/data/cicy3f.README) and [cicy3o.README](http://www.lpthe.jussieu.fr/~erbin/files/data/cicy3o.README) for details on the original data) and includes engineered features (this the papers for details).\n",
    "\n",
    "The code relies on the package `mltools` which I created for my own use: it is automatically downloaded and can be found on Github. I don't guarantee forward compatibility."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QHsappmR2ddK"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import json\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from sklearn import preprocessing, model_selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yNkC30Ec-zDK"
   },
   "outputs": [],
   "source": [
    "if not os.path.exists('mltools.egg'):\n",
    "    !wget http://www.lpthe.jussieu.fr/~erbin/files/data/mltools.egg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "C3F5YQSy_wVn"
   },
   "outputs": [],
   "source": [
    "eggpath = os.path.realpath('./mltools.egg')\n",
    "if eggpath not in sys.path:\n",
    "    sys.path.insert(0, eggpath)\n",
    "\n",
    "import mltools\n",
    "from mltools import CategoricalFeatures, DataStructure, DataExploration\n",
    "from mltools import (LinearRegression, SVM, DecistionTree, RandomForest,\n",
    "                     NeuralNet, RatioSample)\n",
    "from mltools import Logger, Predictions\n",
    "from mltools.data import datatools as dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "g_ptcRWUp9jx"
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XD8cmdQyziI1"
   },
   "source": [
    "## Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ODCa0OYUVBDd"
   },
   "outputs": [],
   "source": [
    "# true = keep outliers\n",
    "OUTLIERS = ('all', 'test', None)[1]\n",
    "SCALEMAT = (True, False)[1]\n",
    "\n",
    "EDA = (True, False)[1]\n",
    "\n",
    "LC = (True, False)[1]\n",
    "FIT = (True, False)[0]\n",
    "\n",
    "LINEAR = (True, False)[0]\n",
    "NONLINEAR = (True, False)[0]\n",
    "\n",
    "CONVNET = (True, False)[1]\n",
    "INCNET = (True, False)[1]\n",
    "ADVNET = (True, False)[1]\n",
    "\n",
    "training_ratio = 0.8\n",
    "samples = RatioSample([training_ratio, 0.1, 0.9 - training_ratio])\n",
    "\n",
    "integers_fn = {\"h11\": np.round, \"h21\": np.round}\n",
    "lin_integers_fn = {\"h11\": np.floor, \"h21\": np.round}\n",
    "\n",
    "metrics = {\"h11\": \"accuracy\", \"h21\": \"accuracy\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cz39FWam2hMb"
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "RESULTPATH = \"./results\"\n",
    "DATAPATH = os.path.realpath(\".\")\n",
    "\n",
    "DATAFILE_FAV = 'cicy3f.h5'\n",
    "DATAFILE_ORIG = 'cicy3o.h5'\n",
    "DATAFILE = DATAFILE_ORIG\n",
    "\n",
    "if not os.path.exists(DATAFILE_FAV):\n",
    "    !wget http://www.lpthe.jussieu.fr/~erbin/files/data/cicy3f.h5\n",
    "if not os.path.exists(DATAFILE_ORIG):\n",
    "    !wget http://www.lpthe.jussieu.fr/~erbin/files/data/cicy3o.h5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gX3lRosMH0az"
   },
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "pd.set_option('display.max_columns', 10)\n",
    "pd.set_option('display.max_rows', 20)\n",
    "pd.set_option('display.float_format', \"{:.3f}\".format)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fsBQHdFIzeMt"
   },
   "source": [
    "## Helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ukMBkPn_2mUO"
   },
   "outputs": [],
   "source": [
    "def load_data(datapath, filename):\n",
    "\n",
    "    return pd.read_hdf(os.path.join(datapath, filename))\n",
    "\n",
    "\n",
    "def filter_outliers(df, h11_max=18, h21_max=70):\n",
    "\n",
    "    h11_cutoff = df['h11'] <= h11_max\n",
    "    h21_cutoff = df['h21'] <= h21_max\n",
    "    notprod = df['isprod'] == 0\n",
    "\n",
    "    return df[notprod & h11_cutoff & h21_cutoff]\n",
    "    # return df[notprod]\n",
    "\n",
    "\n",
    "def outliers_name(filename):\n",
    "    if OUTLIERS is True:\n",
    "        return logger.inserttofilename(filename, \"_outliers\")\n",
    "    else:\n",
    "        return filename\n",
    "\n",
    "\n",
    "def print_results(pred, name=\"\"):\n",
    "    if name != \"\":\n",
    "        name = \" (%s)\" % name\n",
    "\n",
    "    print()\n",
    "    print(\"# Model: {}{}\".format(pred.model.model_name, name))\n",
    "\n",
    "    try:\n",
    "        h11_res = pred.feature_metric(\"h11\", mode=\"text\")\n",
    "        print(\"h11: {}\".format(h11_res))\n",
    "    except KeyError:\n",
    "        pass\n",
    "\n",
    "    try:\n",
    "        h21_res = pred.feature_metric(\"h21\", mode=\"text\")\n",
    "        print(\"h21: {}\".format(h21_res))\n",
    "    except KeyError:\n",
    "        pass\n",
    "    \n",
    "    print()\n",
    "\n",
    "\n",
    "def learning_curve_plot(acc, filename=None, logtime=None):\n",
    "\n",
    "    labels = list(list(list(acc.values())[0].values())[0].keys())\n",
    "\n",
    "    ratios = []\n",
    "\n",
    "    scores_train = {k: [] for k in labels}\n",
    "    scores_test = {k: [] for k in labels}\n",
    "\n",
    "    for x, sc in acc.items():\n",
    "        ratios.append(x)\n",
    "        for k, v in sc['train'].items():\n",
    "            scores_train[k].append(v)\n",
    "        for k, v in sc['test'].items():\n",
    "            scores_test[k].append(v)\n",
    "\n",
    "    scores_train = {k: np.array(v) for k, v in scores_train.items()}\n",
    "    scores_test = {k: np.array(v) for k, v in scores_test.items()}\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "\n",
    "    styles = logger.styles\n",
    "    linestyle = ['solid', 'dashed']\n",
    "\n",
    "    for i, k in enumerate(labels):\n",
    "        if len(scores_train[k].shape) > 1:\n",
    "            train_values = scores_train[k][:, 0]\n",
    "            train_stat = scores_train[k][:, 1]\n",
    "            test_values = scores_test[k][:, 0]\n",
    "            test_stat = scores_test[k][:, 1]\n",
    "        else:\n",
    "            train_values = scores_train[k]\n",
    "            train_stat = None\n",
    "            test_values = scores_test[k]\n",
    "            test_stat = None\n",
    "\n",
    "        ax.plot(ratios, train_values, linestyle=linestyle[i], marker='.',\n",
    "                color=styles[\"color:train\"],\n",
    "                label=\"{} ({})\".format(k, styles[\"label:train\"]))\n",
    "        ax.plot(ratios, test_values, linestyle=linestyle[i], marker='.',\n",
    "                color=styles[\"color:val\"],\n",
    "                label=\"{} ({}.)\".format(k, styles[\"label:val\"][:3]))\n",
    "        \n",
    "        if train_stat is not None:\n",
    "            ax.fill_between(ratios, train_values - train_stat,\n",
    "                    train_values + train_stat,\n",
    "                    alpha=0.3, color=styles[\"color:train\"])\n",
    "            ax.fill_between(ratios, test_values - test_stat,\n",
    "                    test_values + test_stat,\n",
    "                    alpha=0.3, color=styles[\"color:val\"])\n",
    "\n",
    "    ax.legend()\n",
    "\n",
    "    ax.set_xlabel(\"training ratio\")\n",
    "    ax.set_ylabel(\"accuracy\")\n",
    "\n",
    "    ax.set_ylim(ymin=0, ymax=1)\n",
    "\n",
    "    if filename is not None:\n",
    "        logger.save_fig(fig, filename=filename, logtime=logtime)\n",
    "    \n",
    "    plt.close(fig)\n",
    "    \n",
    "    return fig\n",
    "\n",
    "\n",
    "def learning_curve(model_fn, integers_fn, train_params=None, ratios=None,\n",
    "                   filename=None, logtime=True):\n",
    "    \n",
    "    if ratios is None:\n",
    "        ratios = np.arange(0.1, 1.0, 0.1)\n",
    "\n",
    "    metrics = {\"h11\": \"accuracy\", \"h21\": \"accuracy\"}\n",
    "\n",
    "    lc_acc = {}\n",
    "\n",
    "    for x in ratios:\n",
    "        x = np.round(x, 2)\n",
    "\n",
    "        print(\"ratio = \", x)\n",
    "\n",
    "        trainval = cydata_all.sample(frac=x)\n",
    "        test = cydata_all.loc[~cydata_all.index.isin(trainval.index)].sample(frac=1)\n",
    "\n",
    "        if OUTLIERS == 'test':\n",
    "            trainval = filter_outliers(trainval, h11_max=18, h21_max=70)\n",
    "\n",
    "        model = model_fn()\n",
    "\n",
    "        if isinstance(model, NeuralNet):\n",
    "\n",
    "            val = trainval.sample(frac=0.1)\n",
    "            train = trainval.loc[~trainval.index.isin(val.index)].sample(frac=1)\n",
    "\n",
    "            model.fit(train, val_data=[val, val], train_params=train_params)\n",
    "        else:\n",
    "            model.fit(trainval)\n",
    "\n",
    "        lc_pred_test = Predictions(test, model=model, metrics=metrics,\n",
    "                                   integers_fn=integers_fn, logger=logger)\n",
    "\n",
    "        lc_pred_train = Predictions(trainval, model=model, metrics=metrics,\n",
    "                                    integers_fn=integers_fn, logger=logger)\n",
    "\n",
    "        lc_acc[x] = {}\n",
    "        lc_acc[x][\"train\"] = {f: lc_pred_train.feature_metric(f)\n",
    "                              for f in model.outputs.features}\n",
    "        lc_acc[x][\"test\"] = {f: lc_pred_test.feature_metric(f)\n",
    "                             for f in model.outputs.features}\n",
    "\n",
    "        if filename is not None:\n",
    "            logger.save_json(lc_acc, filename=filename + '.json',\n",
    "                             logtime=logtime)\n",
    "            pdfname = filename + '.pdf'\n",
    "        else:\n",
    "            pdfname = None\n",
    "\n",
    "        fig = learning_curve_plot(lc_acc, pdfname, logtime)\n",
    "    \n",
    "    print()\n",
    "    \n",
    "    return fig, lc_acc\n",
    "\n",
    "def train_predict(inputs, outputs, Model, model_params, int_fn, n=1,\n",
    "                  name=\"\", filename=None):\n",
    "    model = Model(inputs=inputs, outputs=outputs, n=n,\n",
    "                  model_params=model_params)\n",
    "    model.fit(cydata['train'])\n",
    "\n",
    "    pred = build_pred(model, int_fn)\n",
    "\n",
    "    print_results(pred, name)\n",
    "\n",
    "    if filename is not None:\n",
    "        pred.summary(filename=filename, density=False, logtime=True)\n",
    "\n",
    "    return pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ImZJwcfBzaX6"
   },
   "source": [
    "## Data and logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "o_V0kNKayDth"
   },
   "outputs": [],
   "source": [
    "logger = Logger(RESULTPATH, logtime=\"folder\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4j08LxBJ2wJn"
   },
   "outputs": [],
   "source": [
    "cydata_all = load_data(DATAPATH, DATAFILE)\n",
    "cydata_all = dt.pad_data(cydata_all)\n",
    "\n",
    "if OUTLIERS is None:\n",
    "    cydata_all = filter_outliers(cydata_all)\n",
    "\n",
    "if SCALEMAT is True:\n",
    "    cydata_all['matrix'] = cydata_all['matrix'].apply(lambda x: x / 5)\n",
    "\n",
    "cydata = samples(cydata_all, shuffle=True)\n",
    "\n",
    "if OUTLIERS == 'test':\n",
    "    cydata['train'] = filter_outliers(cydata['train'])\n",
    "    cydata['val'] = filter_outliers(cydata['val'])\n",
    "\n",
    "def build_pred(model, int_fn):\n",
    "    return Predictions(cydata['test'], model=model, metrics=metrics,\n",
    "                       integers_fn=int_fn, logger=logger)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7fUDE8szILlk"
   },
   "outputs": [],
   "source": [
    "outputs_list = ['h11', 'h21']\n",
    "outputs = DataStructure(outputs_list, infer=cydata_all)\n",
    "h11_outputs = DataStructure(['h11'], infer=cydata_all)\n",
    "h21_outputs = DataStructure(['h21'], infer=cydata_all)\n",
    "outputs = h21_outputs\n",
    "\n",
    "scalar_inputs = ['num_cp']\n",
    "aux_scalar_inputs = ['num_eqs',\n",
    "                     'min_dim_cp', 'max_dim_cp', 'mean_dim_cp', 'median_dim_cp',\n",
    "                     # 'num_cp_1', 'num_cp_2', 'num_cp_neq1',\n",
    "                     'num_over', 'num_ex',\n",
    "                     'max_deg_eqs', 'mean_deg_eqs', 'median_deg_eqs',\n",
    "                     'rank_matrix', 'norm_matrix']\n",
    "all_scalar_inputs = scalar_inputs + aux_scalar_inputs\n",
    "\n",
    "vector_inputs = ['dim_h0_amb', 'dim_cp']\n",
    "aux_vector_inputs = ['num_deg_eqs']\n",
    "# 'num_dim_cp', 'deg_eqs'\n",
    "all_vector_inputs = vector_inputs + aux_vector_inputs\n",
    "\n",
    "matrix_inputs = ['matrix']\n",
    "\n",
    "all_inputs = all_scalar_inputs + all_vector_inputs + matrix_inputs\n",
    "\n",
    "inputs_tab = {\"num_cp\": scalar_inputs,\n",
    "              \"scalar\": all_scalar_inputs,\n",
    "              \"dim_cp_h0\": vector_inputs,\n",
    "              \"vector\": all_vector_inputs,\n",
    "              \"num_dim_cp_h0\": scalar_inputs + vector_inputs,\n",
    "              \"scalar+vector\": all_scalar_inputs + all_vector_inputs,\n",
    "              \"matrix\": matrix_inputs,\n",
    "              \"num_cp\": scalar_inputs + matrix_inputs,\n",
    "              \"matrix+scalar\": all_scalar_inputs + matrix_inputs,\n",
    "              \"matrix+dim_cp_h0\": vector_inputs + matrix_inputs,\n",
    "              \"matrix+vector\": all_vector_inputs + matrix_inputs,\n",
    "              \"all\": all_inputs\n",
    "              }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yIDLDyTqy_zg"
   },
   "source": [
    "## Data exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lYidURiWyKfo"
   },
   "outputs": [],
   "source": [
    "if EDA is True:\n",
    "    \n",
    "    de = DataExploration(logger=logger)\n",
    "    de.summary(cydata_all, filename=\"eda\")\n",
    "    de.summary_io(cydata_all, inputs=all_scalar_inputs, outputs=outputs_list,\n",
    "                filename=\"eda_io_scalar\")\n",
    "    de.importances(cydata_all, outputs=outputs_list,\n",
    "                inputs=all_scalar_inputs + all_vector_inputs + matrix_inputs,\n",
    "                label_rot=90, ymax=0.3, sum_tensor=False,\n",
    "                filename=\"eda_importances\")\n",
    "    de.importances(cydata_all, outputs=outputs_list,\n",
    "                inputs=all_scalar_inputs + all_vector_inputs + matrix_inputs,\n",
    "                sum_tensor=True, filename=\"eda_importances_sum\")\n",
    "    de.importances(cydata_all, outputs=outputs_list,\n",
    "                inputs=all_scalar_inputs, filename=\"eda_importances_scalars\")\n",
    "    de.importances(cydata_all, outputs=outputs_list,\n",
    "                inputs=all_vector_inputs, filename=\"eda_importances_vectors\")\n",
    "    de.importances(cydata_all, outputs=outputs_list,\n",
    "                inputs=matrix_inputs, ymax=0.15,\n",
    "                filename=\"eda_importances_matrix\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "siFo8x_7yyHW"
   },
   "source": [
    "## Linear regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4KdIFjM5mj8J"
   },
   "source": [
    "### Input: matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jJAXVejYmqaA",
    "outputId": "ce8f0f14-4d58-44c6-801b-b6486f6cf88e"
   },
   "outputs": [],
   "source": [
    "inputs_list = ['matrix']\n",
    "inputs = DataStructure(inputs_list)\n",
    "name = 'matrix'\n",
    "\n",
    "model_params = {\"l1\": 0.0002, \"max_iter\": 5000, \"fit_intercept\": False}\n",
    "\n",
    "if LINEAR is True and FIT is True:\n",
    "    pred = train_predict(inputs, outputs, LinearRegression, model_params,\n",
    "                         int_fn=lin_integers_fn, name=name,\n",
    "                         filename=outliers_name(\"linreg_summary_\" + name))\n",
    "\n",
    "if LINEAR is True and LC is True:\n",
    "    model_fn = lambda: LinearRegression(inputs, outputs,\n",
    "                                        model_params=model_params, n=1)\n",
    "\n",
    "    acc, fig = learning_curve(model_fn, lin_integers_fn,\n",
    "                              filename=outliers_name(\"linreg_learning_curve_\" + name))\n",
    "\n",
    "    display(fig)\n",
    "    # print(json.dumps(acc, indent=2))\n",
    "    print(acc)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oWYvaYdgnS-7"
   },
   "source": [
    "### Input: num_cp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cXCxg7b9tQzr"
   },
   "source": [
    "The next cell shows that it's possible to use np.round also for linear regression, but it's very specific and needs some fine tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "K7CcBC8_dW6C",
    "outputId": "87ec6088-984d-47ee-823d-e2c6b1623a9a"
   },
   "outputs": [],
   "source": [
    "inputs_list = ['num_cp']\n",
    "inputs = DataStructure(inputs_list, infer=cydata_all)\n",
    "name = \"num_cp\"\n",
    "\n",
    "model_params = {\"l1\": 5, \"l2\": 0.01, \"max_iter\": 5000, \"fit_intercept\": False}\n",
    "\n",
    "if LINEAR is True:\n",
    "    pred = train_predict(inputs, outputs, LinearRegression, model_params,\n",
    "                         int_fn=lin_integers_fn, name=name, filename=None)\n",
    "    print(\"h11 = %.2f + %.3f #CP\" % (pred.model.model.intercept_, pred.model.model.coef_))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SDxW0-ffrsVq",
    "outputId": "41f42e00-5f21-42d5-f3d0-8d332799b6ce"
   },
   "outputs": [],
   "source": [
    "model_params = {\"l1\": 1, \"max_iter\": 5000, \"fit_intercept\": False}\n",
    "\n",
    "if LINEAR is True and FIT is True:\n",
    "    pred = train_predict(inputs, outputs, LinearRegression, model_params,\n",
    "                         int_fn=lin_integers_fn, name=name,\n",
    "                         filename=outliers_name(\"linreg_summary_\" + name))\n",
    "\n",
    "if LINEAR is True and LC is True:\n",
    "    model_fn = lambda: LinearRegression(inputs, outputs,\n",
    "                                        model_params=model_params, n=1)\n",
    "\n",
    "    acc, fig = learning_curve(model_fn, lin_integers_fn,\n",
    "                              filename=outliers_name(\"linreg_learning_curve_\" + name))\n",
    "\n",
    "    display(fig)\n",
    "    print(acc)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TeIyJpxAuqCY"
   },
   "source": [
    "### Input: vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KDhcrD6D3q2k",
    "outputId": "3524f978-b214-4467-dfaf-90f172e5d283"
   },
   "outputs": [],
   "source": [
    "inputs_list = ['dim_cp', 'dim_h0_amb']\n",
    "inputs = DataStructure(inputs_list, infer=cydata_all)\n",
    "name = \"vectors\"\n",
    "\n",
    "model_params = {\"l1\": 0.01, \"max_iter\": 5000}\n",
    "\n",
    "if LINEAR is True and FIT is True:\n",
    "    pred = train_predict(inputs, outputs, LinearRegression, model_params,\n",
    "                         int_fn=lin_integers_fn, name=name, filename=None)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Do69fyHWzunK"
   },
   "source": [
    "### Inputs: all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hOu19-JEIXVt",
    "outputId": "81edb77d-2578-43cd-c1f5-330174b63910"
   },
   "outputs": [],
   "source": [
    "model_params = {\"l1\": 0.001, \"max_iter\": 5000}\n",
    "\n",
    "#inputs_tab = {\"matrix\": matrix_inputs, \"num_cp\": scalar_inputs}\n",
    "#inputs_tab = {}\n",
    "#inputs_tab = {}\n",
    "\n",
    "if LINEAR is True and FIT is True:\n",
    "\n",
    "    for name, inputs_list in inputs_tab.items():\n",
    "        inputs = DataStructure(inputs_list, infer=cydata_all)\n",
    "        pred = train_predict(inputs, outputs, LinearRegression, model_params,\n",
    "                             int_fn=lin_integers_fn, name=name,\n",
    "                             filename=outliers_name(\"linreg_summary_nonopt_\" + name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BfNrXSKYvnTu",
    "outputId": "f99f78cd-66c2-4031-d62a-f86a7b8831ab"
   },
   "outputs": [],
   "source": [
    "inputs_list = all_inputs\n",
    "inputs = DataStructure(inputs_list, infer=cydata_all)\n",
    "name = \"all\"\n",
    "\n",
    "model_params = {\"l1\": 0.1, \"l2\": 0.001, \"max_iter\": 5000, \"fit_intercept\": False}\n",
    "\n",
    "if LINEAR is True and FIT is True:\n",
    "    pred = train_predict(inputs, outputs, LinearRegression, model_params,\n",
    "                         int_fn=lin_integers_fn, name=name,\n",
    "                         filename=outliers_name(\"linreg_summary_\" + name))\n",
    "\n",
    "if LINEAR is True and LC is True:\n",
    "    model_fn = lambda: LinearRegression(inputs, outputs,\n",
    "                                        model_params=model_params, n=1)\n",
    "\n",
    "    acc, fig = learning_curve(model_fn, lin_integers_fn,\n",
    "                              filename=outliers_name(\"linreg_learning_curve_\" + name))\n",
    "\n",
    "    display(fig)\n",
    "    print(acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FlXeUHiNEaNm"
   },
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MjwYlpL6zgO3"
   },
   "source": [
    "### Input: matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1nT2IiiizgFj",
    "outputId": "ec64ac0a-4add-4815-a48e-57ba33d617ea"
   },
   "outputs": [],
   "source": [
    "inputs_list = ['matrix']\n",
    "inputs = DataStructure(inputs_list)\n",
    "name = 'matrix'\n",
    "\n",
    "model_params = {\"kernel\": \"rbf\", \"C\": 20, \"gamma\": \"scale\", \"epsilon\": 0.1,\n",
    "                \"max_iter\": -1, \"verbose\": 0}\n",
    "\n",
    "if NONLINEAR is True and FIT is True:\n",
    "    pred = train_predict(inputs, outputs, SVM, model_params,\n",
    "                         int_fn=integers_fn, name=name,\n",
    "                         filename=outliers_name(\"svm_summary_\" + name))\n",
    "\n",
    "if NONLINEAR is True and LC is True:\n",
    "    model_fn = lambda: SVM(inputs, outputs, model_params=model_params, n=1)\n",
    "\n",
    "    acc, fig = learning_curve(model_fn, integers_fn,\n",
    "                              filename=outliers_name(\"svm_learning_curve_\" + name))\n",
    "\n",
    "    display(fig)\n",
    "    print(acc)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QX8XgHRyLmDx"
   },
   "source": [
    "### Input: num_cp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oVyx_Nn9LpCa",
    "outputId": "05528f3e-a2c4-4d85-93da-bd73bf743f1c"
   },
   "outputs": [],
   "source": [
    "inputs_list = ['num_cp']\n",
    "inputs = DataStructure(inputs_list)\n",
    "name = 'num_cp'\n",
    "\n",
    "model_params = {\"kernel\": \"rbf\", \"C\": 20, \"gamma\": \"scale\", \"epsilon\": 0.1,\n",
    "                \"max_iter\": -1, \"verbose\": 0}\n",
    "\n",
    "if NONLINEAR is True and FIT is True:\n",
    "    pred = train_predict(inputs, outputs, SVM, model_params,\n",
    "                         int_fn=integers_fn, name=name,\n",
    "                         filename=outliers_name(\"svm_summary_\" + name))\n",
    "\n",
    "if NONLINEAR is True and LC is True:\n",
    "    model_fn = lambda: SVM(inputs, outputs, model_params=model_params, n=1)\n",
    "\n",
    "    acc, fig = learning_curve(model_fn, integers_fn,\n",
    "                                filename=outliers_name(\"svm_learning_curve_\" + name))\n",
    "\n",
    "    display(fig)\n",
    "    print(acc)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NP3BVqFFWv9k"
   },
   "source": [
    "### Input: num_cp + matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ezy8TfzwWzIM",
    "outputId": "567a2ae1-1060-4b1d-dbea-13a50366ef25"
   },
   "outputs": [],
   "source": [
    "inputs_list = ['num_cp', 'matrix']\n",
    "inputs = DataStructure(inputs_list)\n",
    "name = 'num_cp_matrix'\n",
    "\n",
    "model_params = {\"kernel\": \"rbf\", \"C\": 20, \"gamma\": \"scale\", \"epsilon\": 0.1,\n",
    "                \"max_iter\": -1, \"verbose\": 0}\n",
    "\n",
    "if NONLINEAR is True and FIT is True:\n",
    "    pred = train_predict(inputs, outputs, SVM, model_params,\n",
    "                         int_fn=integers_fn, name=name,\n",
    "                         filename=outliers_name(\"svm_summary_\" + name))\n",
    "\n",
    "if NONLINEAR is True and LC is True:\n",
    "    model_fn = lambda: SVM(inputs, outputs, model_params=model_params, n=1)\n",
    "\n",
    "    acc, fig = learning_curve(model_fn, integers_fn,\n",
    "                                filename=outliers_name(\"svm_learning_curve_\" + name))\n",
    "\n",
    "    display(fig)\n",
    "    print(acc)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hLJHy6ITz57h"
   },
   "source": [
    "### Input: vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_twvB52wz5sr",
    "outputId": "765af697-8035-4ed7-aa93-c13e61cfec50"
   },
   "outputs": [],
   "source": [
    "inputs_list = ['dim_cp', 'dim_h0_amb']\n",
    "inputs = DataStructure(inputs_list)\n",
    "name = 'vectors'\n",
    "\n",
    "model_params = {\"kernel\": \"rbf\", \"C\": 10, \"gamma\": \"scale\", \"epsilon\": 0.1,\n",
    "                \"max_iter\": -1, \"verbose\": 0}\n",
    "\n",
    "if NONLINEAR is True and FIT is True:\n",
    "    pred = train_predict(inputs, outputs, SVM, model_params,\n",
    "                         int_fn=integers_fn, name=name,\n",
    "                         filename=outliers_name(\"svm_summary_\" + name))\n",
    "\n",
    "# if NONLINEAR is True and LC is True:\n",
    "#     model_fn = lambda: SVM(inputs, outputs, model_params=model_params, n=1)\n",
    "\n",
    "#     acc, fig = learning_curve(model_fn, integers_fn,\n",
    "#                               filename=outliers_name(\"svm_learning_curve_\" + name))\n",
    "\n",
    "#     display(fig)\n",
    "#     # print(json.dumps(acc, indent=2))\n",
    "#     print(acc)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lFPaDbGWzfz2"
   },
   "source": [
    "### Input: all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RIr0EGOl4VWz",
    "outputId": "62bf0bd8-d285-41f6-ecb0-ddad3c65d815"
   },
   "outputs": [],
   "source": [
    "model_params = {\"kernel\": \"rbf\", \"C\": 30, \"gamma\": 0.03, \"epsilon\": 0.1,\n",
    "                \"max_iter\": -1, \"verbose\": 0}\n",
    "\n",
    "#inputs_tab = {\"matrix\": matrix_inputs, \"num_cp\": scalar_inputs}\n",
    "#inputs_tab = {}\n",
    "#inputs_tab = {}\n",
    "\n",
    "if NONLINEAR is True and FIT is True:\n",
    "\n",
    "    for name, inputs_list in inputs_tab.items():\n",
    "        inputs = DataStructure(inputs_list, infer=cydata_all)\n",
    "        pred = train_predict(inputs, outputs, SVM, model_params,\n",
    "                             int_fn=integers_fn, name=name,\n",
    "                             filename=outliers_name(\"svm_summary_nonopt_\" + name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "P-9GRpF_2YuG",
    "outputId": "0abb3676-add3-4423-8d9d-6b461f99baff"
   },
   "outputs": [],
   "source": [
    "inputs_list = all_inputs\n",
    "# inputs_list = ['matrix', 'num_cp', 'norm_matrix', 'dim_cp', 'dim_h0_amb']\n",
    "inputs = DataStructure(inputs_list)\n",
    "name = 'all'\n",
    "\n",
    "model_params = {\"kernel\": \"rbf\", \"C\": 1, \"gamma\": \"scale\", \"epsilon\": 0.1,\n",
    "                \"max_iter\": -1, \"verbose\": 0}\n",
    "\n",
    "if NONLINEAR is True and FIT is True:\n",
    "    pred = train_predict(inputs, outputs, SVM, model_params,\n",
    "                         int_fn=integers_fn, name=name,\n",
    "                         filename=outliers_name(\"svm_summary_\" + name))\n",
    "\n",
    "if NONLINEAR is True and LC is True:\n",
    "    model_fn = lambda: SVM(inputs, outputs, model_params=model_params, n=1)\n",
    "\n",
    "    acc, fig = learning_curve(model_fn, integers_fn,\n",
    "                              filename=outliers_name(\"svm_learning_curve_\" + name))\n",
    "\n",
    "    display(fig)\n",
    "    print(acc)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_5BoP98O38bd"
   },
   "source": [
    "## Decision trees"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4Pb1Dqwt4ITn"
   },
   "source": [
    "### Input: matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5nGwRye64ITq"
   },
   "outputs": [],
   "source": [
    "inputs_list = ['matrix']\n",
    "inputs = DataStructure(inputs_list)\n",
    "name = 'matrix'\n",
    "\n",
    "model_params = {\"max_depth\": None, \"min_samples_split\": 2,\n",
    "                \"min_samples_leaf\": 1, \"max_leaf_nodes\": None}\n",
    "\n",
    "# if NONLINEAR is True and FIT is True:\n",
    "#     pred = train_predict(inputs, outputs, DecistionTree, model_params,\n",
    "#                          int_fn=integers_fn, name=name,\n",
    "#                          filename=outliers_name(\"tree_summary_\" + name))\n",
    "\n",
    "# if LINEAR is True and LC is True:\n",
    "#     model_fn = lambda: LinearRegression(inputs, outputs,\n",
    "#                                         model_params=model_params, n=1)\n",
    "\n",
    "#     acc, fig = learning_curve(model_fn, lin_integers_fn,\n",
    "#                               filename=outliers_name(\"linreg_learning_curve_\" + name))\n",
    "\n",
    "#     display(fig)\n",
    "#     # print(json.dumps(acc, indent=2))\n",
    "#     print(acc)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P78Stix74Q9y"
   },
   "source": [
    "### Inputs: all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xUe-Telo4Q92"
   },
   "outputs": [],
   "source": [
    "model_params = {\"max_depth\": None, \"min_samples_split\": 2,\n",
    "                \"min_samples_leaf\": 1, \"max_leaf_nodes\": None}\n",
    "\n",
    "#inputs_tab = {\"matrix\": matrix_inputs, \"num_cp\": scalar_inputs}\n",
    "#inputs_tab = {}\n",
    "#inputs_tab = {}\n",
    "\n",
    "# if NONLINEAR is True and FIT is True:\n",
    "\n",
    "#     for name, inputs_list in inputs_tab.items():\n",
    "#         inputs = DataStructure(inputs_list, infer=cydata_all)\n",
    "#         pred = train_predict(inputs, outputs, DecisionTree, model_params,\n",
    "#                              int_fn=integers_fn, name=name,\n",
    "#                              filename=outliers_name(\"tree_summary_nonopt_\" + name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6IkAjv5T4Q-E"
   },
   "outputs": [],
   "source": [
    "inputs_list = all_inputs\n",
    "inputs = DataStructure(inputs_list, infer=cydata_all)\n",
    "name = \"all\"\n",
    "\n",
    "model_params = {\"max_depth\": None, \"min_samples_split\": 2,\n",
    "                \"min_samples_leaf\": 1, \"max_leaf_nodes\": None}\n",
    "\n",
    "# if NONLINEAR is True and FIT is True:\n",
    "#     pred = train_predict(inputs, outputs, DecistionTree, model_params,\n",
    "#                          int_fn=integers_fn, name=name,\n",
    "#                          filename=outliers_name(\"tree_summary_\" + name))\n",
    "\n",
    "# if NONLINEAR is True and LC is True:\n",
    "#     model_fn = lambda: DecistionTree(inputs, outputs,\n",
    "#                                      model_params=model_params, n=1)\n",
    "\n",
    "#     acc, fig = learning_curve(model_fn, integers_fn,\n",
    "#                               filename=outliers_name(\"tree_learning_curve_\" + name))\n",
    "\n",
    "#     display(fig)\n",
    "#     print(acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TWEcDsUXEipV"
   },
   "source": [
    "## Random forests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q7ra2CQV4KRR"
   },
   "source": [
    "### Input: matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZmiImxD44KRU",
    "outputId": "6ad5ecb5-4857-4c1f-d74d-540f00ab87c9"
   },
   "outputs": [],
   "source": [
    "inputs_list = ['matrix']\n",
    "inputs = DataStructure(inputs_list)\n",
    "name = 'matrix'\n",
    "\n",
    "model_params = {\"n_estimators\": 300, \"max_depth\": None,\n",
    "                \"min_samples_split\": 2, \"min_samples_leaf\": 1,\n",
    "                \"max_leaf_nodes\": None, \"max_samples\": None}\n",
    "\n",
    "if NONLINEAR is True and FIT is True:\n",
    "    pred = train_predict(inputs, outputs, RandomForest, model_params,\n",
    "                         int_fn=integers_fn, name=name,\n",
    "                         filename=outliers_name(\"forest_summary_\" + name))\n",
    "\n",
    "if NONLINEAR is True and LC is True:\n",
    "    model_fn = lambda: RandomForest(inputs, outputs,\n",
    "                                        model_params=model_params, n=1)\n",
    "\n",
    "    acc, fig = learning_curve(model_fn, lin_integers_fn,\n",
    "                              filename=outliers_name(\"forest_learning_curve_\" + name))\n",
    "\n",
    "    display(fig)\n",
    "    # print(json.dumps(acc, indent=2))\n",
    "    print(acc)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P3wFa2KH4SDZ"
   },
   "source": [
    "### Inputs: all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "y3WHR-1x4SDb",
    "outputId": "40f50073-a3b3-4db3-9633-11c9925cce4a"
   },
   "outputs": [],
   "source": [
    "model_params = {\"n_estimators\": 300, \"max_depth\": None,\n",
    "                \"min_samples_split\": 2, \"min_samples_leaf\": 1,\n",
    "                \"max_leaf_nodes\": None, \"max_samples\": None}\n",
    "\n",
    "#inputs_tab = {\"matrix\": matrix_inputs, \"num_cp\": scalar_inputs}\n",
    "#inputs_tab = {}\n",
    "#inputs_tab = {}\n",
    "\n",
    "if NONLINEAR is True and FIT is True:\n",
    "\n",
    "    for name, inputs_list in inputs_tab.items():\n",
    "        inputs = DataStructure(inputs_list, infer=cydata_all)\n",
    "        pred = train_predict(inputs, outputs, RandomForest, model_params,\n",
    "                             int_fn=integers_fn, name=name,\n",
    "                             filename=outliers_name(\"forest_summary_nonopt_\" + name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zkCrKnQ34SDj",
    "outputId": "fe48189c-64b8-43ab-e453-3e89b9ab37b0"
   },
   "outputs": [],
   "source": [
    "inputs_list = all_inputs\n",
    "inputs = DataStructure(inputs_list, infer=cydata_all)\n",
    "name = \"all\"\n",
    "\n",
    "model_params = {\"n_estimators\": 100, \"max_depth\": None,\n",
    "                \"min_samples_split\": 2, \"min_samples_leaf\": 1,\n",
    "                \"max_leaf_nodes\": None, \"max_samples\": None}\n",
    "\n",
    "if NONLINEAR is True and FIT is True:\n",
    "    pred = train_predict(inputs, outputs, RandomForest, model_params,\n",
    "                         int_fn=lin_integers_fn, name=name,\n",
    "                         filename=outliers_name(\"forest_summary_\" + name))\n",
    "\n",
    "if NONLINEAR is True and LC is True:\n",
    "    model_fn = lambda: RandomForest(inputs, outputs,\n",
    "                                    model_params=model_params, n=1)\n",
    "\n",
    "    acc, fig = learning_curve(model_fn, lin_integers_fn,\n",
    "                              filename=outliers_name(\"forest_learning_curve_\" + name))\n",
    "\n",
    "    display(fig)\n",
    "    print(acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oiPdSFH2zlkp"
   },
   "source": [
    "## Neural networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IMnKmjBMznFI"
   },
   "source": [
    "### Convolutional model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "769SdKVkIkTG"
   },
   "outputs": [],
   "source": [
    "def simple_model(inputs, outputs=None,\n",
    "                 lr=0.001, l1=0., l2=0., momentum=0.9,\n",
    "                 Ndense=4, Nconv=4,\n",
    "                 gen_dropout_conv=0., gen_dropout_dense=0.,\n",
    "                 dropout_conv=0., dropout_dense=0.,\n",
    "                 alpha=0.1,\n",
    "                 kernel_size=(4, 4), pool_size=(4, 4),\n",
    "                 optimizer='adam', loss='mse', rho=0.5):\n",
    "\n",
    "    # rho: h11 loss weight\n",
    "\n",
    "    if isinstance(Ndense, int):\n",
    "        Ndense = [Ndense]\n",
    "    if isinstance(Nconv, int):\n",
    "        Nconv = [Nconv]\n",
    "\n",
    "    if optimizer == 'rmsprop':\n",
    "        optimizer = keras.optimizers.RMSprop(lr=lr)\n",
    "    else:\n",
    "        optimizer = keras.optimizers.Adam(lr=lr)\n",
    "\n",
    "    l1l2_reg = keras.regularizers.l1_l2(l1=l1, l2=l2)\n",
    "\n",
    "    input_layers = {}\n",
    "    output_layers = {}\n",
    "\n",
    "    # tf.keras.backend.cast(input, dtype='float64')\n",
    "\n",
    "    matrix_input = layers.Input(shape=inputs.shapes[\"matrix\"],\n",
    "                                name=\"matrix_input\")\n",
    "\n",
    "    input_layers[\"matrix\"] = matrix_input\n",
    "\n",
    "    x = matrix_input\n",
    "\n",
    "    for i, units in enumerate(Nconv):\n",
    "        x = layers.Conv2D(units, kernel_size, padding='same',\n",
    "                          kernel_regularizer=l1l2_reg)(x)\n",
    "        x = layers.BatchNormalization(momentum=momentum)(x)\n",
    "        x = layers.LeakyReLU(alpha=alpha)(x)\n",
    "        x = layers.Dropout(dropout_conv)(x)\n",
    "\n",
    "    x = layers.Flatten()(x)\n",
    "    # x = layers.GlobalMaxPooling2D()(x)\n",
    "\n",
    "    if gen_dropout_conv > 0:\n",
    "        x = layers.Dropout(gen_dropout_conv)(x)\n",
    "\n",
    "    conv_output = x\n",
    "\n",
    "    # general dense layers\n",
    "\n",
    "    for units in Ndense:\n",
    "        x = layers.Dense(units, kernel_regularizer=l1l2_reg)(x)\n",
    "        x = layers.BatchNormalization(momentum=momentum)(x)\n",
    "        x = layers.LeakyReLU(alpha=alpha)(x)\n",
    "\n",
    "    if (gen_dropout_conv == 0 or len(Ndense) > 0) and gen_dropout_dense > 0:\n",
    "        x = layers.Dropout(gen_dropout_dense)(x)\n",
    "\n",
    "    h11_output = layers.Dense(1, name=\"h11_output\")(x)\n",
    "    h21_output = layers.Dense(1, name=\"h21_output\")(x)\n",
    "\n",
    "    if \"h11\" in outputs.features:\n",
    "        output_layers[\"h11\"] = h11_output\n",
    "    if \"h21\" in outputs.features:\n",
    "        output_layers[\"h21\"] = h21_output\n",
    "\n",
    "    if \"h11\" in outputs.features and \"h21\" in outputs.features:\n",
    "        loss_weights = {\"h11_output\": rho, \"h21_output\": 1 - rho}\n",
    "    else:\n",
    "        loss_weights = None\n",
    "\n",
    "    model = keras.models.Model(inputs=input_layers, outputs=output_layers)\n",
    "\n",
    "    model.compile(optimizer=optimizer, loss=loss, loss_weights=loss_weights,\n",
    "                  metrics=['mse', 'mae'])\n",
    "\n",
    "    return {\"model\": model}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Zm3wYMT_ynAm"
   },
   "outputs": [],
   "source": [
    "simple_nn_inputs = DataStructure(matrix_inputs, infer=cydata_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4QXRNP_CNaOQ"
   },
   "outputs": [],
   "source": [
    "%%script false\n",
    "\n",
    "bhjm_model_params = {\"optimizer\": \"adam\",\n",
    "                     \"loss\": \"mse\",\n",
    "                     \"lr\": 0.001,\n",
    "                     \"l2\": 0.0001,\n",
    "                     \"momentum\": 0.99,\n",
    "                     \"alpha\": 0.,\n",
    "                     \"dropout_dense\": 0.2,\n",
    "                     \"Nconv\": [],\n",
    "                     \"Ndense\": [875, 460, 440, 930],\n",
    "                     \"rho\": 0.5\n",
    "                     }\n",
    "bhjm_train_params = {\"epochs\": 500,\n",
    "                     \"batch_size\": 64,\n",
    "                     \"verbose\": 0,\n",
    "                     \"early_stopping\": (1e-4, 50)\n",
    "                     }\n",
    "\n",
    "bhjm_nn = NeuralNet(simple_model, simple_nn_inputs, h11_outputs,\n",
    "                    model_params=bhjm_model_params, n=5)\n",
    "bhjm_nn.fit(cydata, train_params=bhjm_train_params)\n",
    "bhjm_nn_pred = build_pred(bhjm_nn, integers_fn)\n",
    "print_results(bhjm_nn_pred)\n",
    "bhjm_nn_pred.summary(filename=\"bhjm_nn\", density=False, logtime=True,\n",
    "                      training_metrics=['loss']);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YYbZv1s4xzdg"
   },
   "outputs": [],
   "source": [
    "conv_model_params = {\"optimizer\": \"adam\",\n",
    "                     \"loss\": \"mse\",\n",
    "                     \"lr\": 0.001,\n",
    "                     \"l1\": 1e-5,\n",
    "                     \"l2\": 1e-5,\n",
    "                     \"momentum\": 0.99,\n",
    "                     \"alpha\": 0.,\n",
    "                     \"gen_dropout_conv\": 0.2,\n",
    "                     \"dropout_conv\": 0.,\n",
    "                     \"dropout_dense\": 0.,\n",
    "                     \"kernel_size\": (3, 3),\n",
    "                    #  \"Nconv\": [250, 150, 100, 20],\n",
    "                     \"Nconv\": [180, 100, 40, 20],\n",
    "                     \"Ndense\": [],\n",
    "                     \"rho\": 0.5\n",
    "                     }\n",
    "conv_train_params = {\"epochs\": 2000,\n",
    "                     \"batch_size\": 32,\n",
    "                     \"verbose\": 0,\n",
    "                     \"early_stopping\": (1e-4, 150),\n",
    "                     \"reduce_lr\": (0.3, 75)\n",
    "                     }\n",
    "\n",
    "if CONVNET is True and FIT is True:\n",
    "\n",
    "    conv_nn = NeuralNet(simple_model, simple_nn_inputs, h11_outputs,\n",
    "                        model_params=conv_model_params, n=1)\n",
    "    conv_nn.fit(cydata, train_params=conv_train_params)\n",
    "    conv_nn_pred = build_pred(conv_nn, integers_fn)\n",
    "    print_results(conv_nn_pred)\n",
    "    conv_nn_pred.summary(filename=outliers_name(\"conv_nn_summary\"), density=False, logtime=True,\n",
    "                        training_metrics=['loss']);\n",
    "\n",
    "if CONVNET is True and LC is True:\n",
    "    ratios = [0.3, 0.8]\n",
    "    model_fn = lambda: NeuralNet(simple_model, simple_nn_inputs, h11_outputs,\n",
    "                                 model_params=conv_model_params, n=3)\n",
    "    fig, acc = learning_curve(model_fn, integers_fn, ratios=ratios,\n",
    "                              filename=outliers_name(\"conv_nn_learning_curve\"),\n",
    "                              train_params=conv_train_params)\n",
    "    fig\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Di7XGuqrz01k"
   },
   "source": [
    "### Inception model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jnV9cEVI88OT"
   },
   "outputs": [],
   "source": [
    "def inception_model(inputs, outputs=None,\n",
    "                    lr=0.001, l1=0., l2=0., momentum=0.9,\n",
    "                    Ndense=32, Nconv=32,\n",
    "                    dropout_conv=0., dropout_dense=0.,\n",
    "                    alpha=0.1,\n",
    "                    optimizer='adam', loss='mse', rho=0.5):\n",
    "\n",
    "    if isinstance(Ndense, int):\n",
    "        Ndense = [Ndense]\n",
    "    if isinstance(Nconv, int):\n",
    "        Nconv = [Nconv]\n",
    "\n",
    "    if optimizer == 'rmsprop':\n",
    "        optimizer = keras.optimizers.RMSprop(lr=lr)\n",
    "    else:\n",
    "        optimizer = keras.optimizers.Adam(lr=lr)\n",
    "\n",
    "    l1l2_reg = keras.regularizers.l1_l2(l1=l1, l2=l2)\n",
    "\n",
    "    input_layers = {}\n",
    "    output_layers = {}\n",
    "\n",
    "    matrix_input = layers.Input(shape=inputs.shapes[\"matrix\"],\n",
    "                                name=\"matrix_input\")\n",
    "\n",
    "    input_layers[\"matrix\"] = matrix_input\n",
    "\n",
    "    x = matrix_input\n",
    "\n",
    "    for i, units in enumerate(Nconv):\n",
    "        kernel1 = (1, inputs.shapes['matrix'][1])\n",
    "        # kernel1 = (3, 3)\n",
    "\n",
    "        x1 = layers.Conv2D(units, kernel1,\n",
    "                           padding='same', kernel_regularizer=l1l2_reg)(x)\n",
    "        x1 = layers.LeakyReLU(alpha=alpha)(x1)\n",
    "\n",
    "        kernel2 = (inputs.shapes['matrix'][0], 1)\n",
    "        # kernel2 = (5, 5)\n",
    "        x2 = layers.Conv2D(units, kernel2,\n",
    "                           padding='same', kernel_regularizer=l1l2_reg)(x)\n",
    "        x2 = layers.LeakyReLU(alpha=alpha)(x2)\n",
    "\n",
    "        x = layers.concatenate([x1, x2])\n",
    "        x = layers.BatchNormalization(momentum=momentum)(x)\n",
    "\n",
    "    if dropout_conv > 0:\n",
    "        x = layers.Dropout(dropout_conv)(x)\n",
    "\n",
    "    x = layers.Flatten()(x)\n",
    "\n",
    "    # general dense layers\n",
    "\n",
    "    for units in Ndense:\n",
    "        x = layers.Dense(units, kernel_regularizer=l1l2_reg)(x)\n",
    "        x = layers.LeakyReLU(alpha=alpha)(x)\n",
    "        x = layers.BatchNormalization(momentum=momentum)(x)\n",
    "\n",
    "    if len(Ndense) > 0 and dropout_dense > 0:\n",
    "        x = layers.Dropout(dropout_dense)(x)\n",
    "\n",
    "    h11_output = layers.Dense(1, activation=\"relu\", name=\"h11_output\")(x)\n",
    "    h21_output = layers.Dense(1, activation=\"relu\", name=\"h21_output\")(x)\n",
    "\n",
    "    if \"h11\" in outputs.features:\n",
    "        output_layers[\"h11\"] = h11_output\n",
    "    if \"h21\" in outputs.features:\n",
    "        output_layers[\"h21\"] = h21_output\n",
    "\n",
    "    if \"h11\" in outputs.features and \"h21\" in outputs.features:\n",
    "        loss_weights = {\"h11_output\": rho, \"h21_output\": 1 - rho}\n",
    "    else:\n",
    "        loss_weights = None\n",
    "\n",
    "    model = keras.models.Model(inputs=input_layers, outputs=output_layers)\n",
    "\n",
    "    model.compile(optimizer=optimizer, loss=loss, loss_weights=loss_weights,\n",
    "                  metrics=['mse', 'mae'])\n",
    "\n",
    "    return {\"model\": model}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Q6PHNLGZFcuj"
   },
   "outputs": [],
   "source": [
    "inc_outputs = h11_outputs\n",
    "# inc_outputs = outputs\n",
    "\n",
    "inc_model_params = {\"optimizer\": \"adam\",\n",
    "                    \"loss\": \"mse\",\n",
    "                    \"lr\": 0.001,\n",
    "                    \"l1\": 1e-4,\n",
    "                    \"l2\": 1e-4,\n",
    "                    \"momentum\": 0.99,\n",
    "                    \"alpha\": 0.,\n",
    "                    \"dropout_conv\": 0.2,\n",
    "                    \"dropout_dense\": 0.,\n",
    "                    \"Nconv\": [32, 64, 32],\n",
    "                    \"Ndense\": [],\n",
    "                    \"rho\": 0.5\n",
    "                    }\n",
    "inc_train_params = {\"epochs\": 2000,\n",
    "                    \"batch_size\": 32,\n",
    "                    \"verbose\": 0,\n",
    "                    \"early_stopping\": (1e-4, 200),\n",
    "                    \"reduce_lr\": (0.3, 75)\n",
    "                    }\n",
    "\n",
    "if INCNET is True and FIT is True:\n",
    "    inc_nn = NeuralNet(inception_model, simple_nn_inputs, inc_outputs,\n",
    "                        model_params=inc_model_params, n=3)\n",
    "    inc_nn.fit(cydata, train_params=inc_train_params)\n",
    "    inc_nn_pred = build_pred(inc_nn, integers_fn)\n",
    "    print_results(inc_nn_pred)\n",
    "    inc_nn_pred.summary(filename=outliers_name(\"inc_nn_summary\"), density=False,\n",
    "                        logtime=True, training_metrics=['loss']);\n",
    "    \n",
    "    inc_nn_pred.training_curve(\"mae\", filename=\"h11_training_curve_mae.pdf\", logtime=True)\n",
    "    inc_nn_pred.training_curve(\"mse\", filename=\"h11_training_curve_mse.pdf\", logtime=True)\n",
    "    inc_nn_pred.plot_feature(\"h11\", plottype=\"plain\", sigma=0, filename=\"h11_dist_pred_plain.pdf\", logtime=True)\n",
    "    inc_nn_pred.plot_feature(\"h11\", plottype=\"step\", sigma=0, filename=\"h11_dist_pred_step.pdf\", logtime=True)\n",
    "\n",
    "if INCNET is True and LC is True:\n",
    "\n",
    "    ratios = [0.3, 0.8]\n",
    "    # ratios = None\n",
    "    suffix = \"_1d_kernel_out\"\n",
    "\n",
    "    model_fn = lambda: NeuralNet(inception_model, simple_nn_inputs, inc_outputs,\n",
    "                                 model_params=inc_model_params, n=2)\n",
    "    fig, acc = learning_curve(model_fn, integers_fn, ratios=ratios,\n",
    "                              filename=outliers_name(\"inc_nn_learning_curve\" + suffix),\n",
    "                              train_params=inc_train_params)\n",
    "    fig\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_YeZGgAbd2sV"
   },
   "outputs": [],
   "source": [
    "%%script false\n",
    "\n",
    "lc_outputs = h11_outputs\n",
    "# lc_outputs = outputs\n",
    "\n",
    "inc_model_params = {\"optimizer\": \"adam\",\n",
    "                    \"loss\": \"mse\",\n",
    "                    \"lr\": 0.001,\n",
    "                    \"l1\": 1e-4,\n",
    "                    \"l2\": 1e-3,\n",
    "                    \"momentum\": 0.99,\n",
    "                    \"alpha\": 0.,\n",
    "                    \"dropout_conv\": 0.2,\n",
    "                    \"dropout_dense\": 0.,\n",
    "                    \"Nconv\": [32, 64, 32],\n",
    "                    \"Ndense\": [],\n",
    "                    \"rho\": 0.5\n",
    "                    }\n",
    "inc_train_params = {\"epochs\": 2000,\n",
    "                    \"batch_size\": 32,\n",
    "                    \"verbose\": 0,\n",
    "                    \"early_stopping\": (1e-4, 200),\n",
    "                    \"reduce_lr\": (0.3, 75)\n",
    "                    }\n",
    "\n",
    "ratios = np.arange(0.1, 1, 0.1)\n",
    "model_fn = lambda: NeuralNet(inception_model, simple_nn_inputs, h11_outputs,\n",
    "                             model_params=inc_model_params, n=5)\n",
    "fig, acc = learning_curve(model_fn, integers_fn, ratios=ratios,\n",
    "                          filename=outliers_name(\"inc_nn_learning_curve_stat\"),\n",
    "                          train_params=inc_train_params)\n",
    "fig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "idlzMgbEz7Qb"
   },
   "source": [
    "### Advanced model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FPIMBo6YIChm"
   },
   "outputs": [],
   "source": [
    "def advanced_model(inputs, outputs=None,\n",
    "                   lr=0.001, l1=0., l2=0., momentum=0.9,\n",
    "                   Ndense=32, Nconv=32,\n",
    "                   dropout_conv=0., dropout_dense=0.,\n",
    "                   alpha=0.1,\n",
    "                   optimizer='adam', loss='mse', rho=0.5):\n",
    "\n",
    "    if isinstance(Ndense, int):\n",
    "        Ndense = [Ndense]\n",
    "    if isinstance(Nconv, int):\n",
    "        Nconv = [Nconv]\n",
    "\n",
    "    if optimizer == 'rmsprop':\n",
    "        optimizer = keras.optimizers.RMSprop(lr=lr)\n",
    "    else:\n",
    "        optimizer = keras.optimizers.Adam(lr=lr)\n",
    "\n",
    "    l1l2_reg = keras.regularizers.l1_l2(l1=l1, l2=l2)\n",
    "\n",
    "    input_layers = {}\n",
    "    output_layers = {}\n",
    "\n",
    "    matrix_input = layers.Input(shape=inputs.shapes[\"matrix\"],\n",
    "                                name=\"matrix_input\")\n",
    "\n",
    "    num_cp_input = layers.Input(shape=(1,), name=\"num_cp_input\")\n",
    "    num_eqs_input = layers.Input(shape=(1,), name=\"num_eqs_input\")\n",
    "    norm_matrix_input = layers.Input(shape=(1,), name=\"norm_matrix_input\")\n",
    "\n",
    "    dim_cp_input = layers.Input(shape=inputs.shapes[\"dim_cp\"],\n",
    "                                name=\"dim_cp_input\")\n",
    "    dim_h0_amb_input = layers.Input(shape=inputs.shapes[\"dim_h0_amb\"],\n",
    "                                    name=\"dim_h0_amb_input\")\n",
    "\n",
    "    input_layers[\"matrix\"] = matrix_input\n",
    "    input_layers[\"num_cp\"] = num_cp_input\n",
    "    input_layers[\"num_eqs\"] = num_eqs_input\n",
    "    input_layers[\"norm_matrix\"] = norm_matrix_input\n",
    "    input_layers[\"dim_cp\"] = dim_cp_input\n",
    "    input_layers[\"dim_h0_amb\"] = dim_h0_amb_input\n",
    "\n",
    "    # matrix process\n",
    "\n",
    "    x = matrix_input\n",
    "\n",
    "    for i, units in enumerate(Nconv):\n",
    "        x1 = layers.Conv2D(units, (1, 15), padding='same',\n",
    "                           kernel_regularizer=l1l2_reg)(x)\n",
    "        x1 = layers.LeakyReLU(alpha=alpha)(x1)\n",
    "\n",
    "        x2 = layers.Conv2D(units, (12, 1), padding='same',\n",
    "                           kernel_regularizer=l1l2_reg)(x)\n",
    "        x2 = layers.LeakyReLU(alpha=alpha)(x2)\n",
    "\n",
    "        x = layers.concatenate([x1, x2])\n",
    "        x = layers.BatchNormalization(momentum=momentum)(x)\n",
    "\n",
    "    if dropout_conv > 0:\n",
    "        x = layers.Dropout(dropout_conv)(x)\n",
    "\n",
    "    matrix_result = layers.Flatten()(x)\n",
    "\n",
    "    # scalars and dim_cp process\n",
    "\n",
    "    x = layers.concatenate([num_cp_input, num_eqs_input,\n",
    "                            # norm_matrix_input,\n",
    "                            # layers.Flatten()(dim_h0_amb_input),\n",
    "                            layers.Flatten()(dim_cp_input)\n",
    "                            ])\n",
    "\n",
    "    for units in Ndense:\n",
    "        x = layers.Dense(units, kernel_regularizer=l1l2_reg)(x)\n",
    "        x = layers.LeakyReLU(alpha=alpha)(x)\n",
    "        x = layers.BatchNormalization(momentum=momentum)(x)\n",
    "\n",
    "    if len(Ndense) > 0 and dropout_dense > 0:\n",
    "        x = layers.Dropout(dropout_dense)(x)\n",
    "\n",
    "    sc_vec_result = x\n",
    "\n",
    "    # predict h11\n",
    "\n",
    "    x = layers.concatenate([num_cp_input, matrix_result])\n",
    "\n",
    "    h11_output = layers.Dense(1, activation=\"relu\", name=\"h11_output\")(x)\n",
    "\n",
    "    # predict h21\n",
    "\n",
    "    if \"h11\" in outputs.features:\n",
    "        x = layers.concatenate([h11_output, sc_vec_result, matrix_result,\n",
    "                                layers.Flatten()(dim_h0_amb_input)\n",
    "                                ])\n",
    "    else:\n",
    "        x = layers.concatenate([sc_vec_result, matrix_result,\n",
    "                                layers.Flatten()(dim_h0_amb_input),\n",
    "                                ])\n",
    "\n",
    "    h21_output = layers.Dense(1, activation=\"relu\", name=\"h21_output\")(x)\n",
    "\n",
    "    if \"h11\" in outputs.features:\n",
    "        output_layers[\"h11\"] = h11_output\n",
    "    if \"h21\" in outputs.features:\n",
    "        output_layers[\"h21\"] = h21_output\n",
    "\n",
    "    if \"h11\" in outputs.features and \"h21\" in outputs.features:\n",
    "        loss_weights = {\"h11_output\": rho, \"h21_output\": 1 - rho}\n",
    "    else:\n",
    "        loss_weights = None\n",
    "\n",
    "    model = keras.models.Model(inputs=input_layers, outputs=output_layers)\n",
    "\n",
    "    model.compile(optimizer=optimizer, loss=loss, loss_weights=loss_weights,\n",
    "                  metrics=['mse', 'mae'])\n",
    "\n",
    "    return {\"model\": model}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "m4ZIx5oExCGk"
   },
   "outputs": [],
   "source": [
    "adv_model_params = {\"optimizer\": \"adam\",\n",
    "                    \"loss\": \"mse\",\n",
    "                    \"lr\": 0.001,\n",
    "                    \"l1\": 1e-4,\n",
    "                    \"l2\": 1e-4,\n",
    "                    \"momentum\": 0.9,\n",
    "                    \"alpha\": 0.1,\n",
    "                    \"dropout_conv\": 0.2,\n",
    "                    \"dropout_dense\": 0.2,\n",
    "                    \"Nconv\": [32, 32],\n",
    "                    \"Ndense\": [30],\n",
    "                    \"rho\": 0.4\n",
    "                    }\n",
    "adv_train_params = {\"epochs\": 2000,\n",
    "                    \"batch_size\": 32,\n",
    "                    \"verbose\": 0,\n",
    "                    \"early_stopping\": (1e-4, 150),\n",
    "                    \"reduce_lr\": (0.3, 50)\n",
    "                    }\n",
    "\n",
    "if ADVNET is True and FIT is True:\n",
    "\n",
    "    adv_nn_inputs_list = [\"matrix\", \"num_cp\", \"num_eqs\", \"norm_matrix\",\n",
    "                        \"dim_cp\", \"dim_h0_amb\"]\n",
    "    adv_nn_inputs = DataStructure(adv_nn_inputs_list, infer=cydata_all)\n",
    "\n",
    "    adv_nn = NeuralNet(advanced_model, adv_nn_inputs, outputs,\n",
    "                    model_params=adv_model_params, n=1)\n",
    "    adv_nn.fit(cydata, train_params=adv_train_params)\n",
    "    adv_nn_pred = build_pred(adv_nn, integers_fn)\n",
    "    print_results(adv_nn_pred)\n",
    "    adv_nn_pred.summary(filename=outliers_name(\"adv_nn_summary\"), density=False,\n",
    "                        logtime=True, training_metrics=['loss']);\n",
    "\n",
    "ratios = np.arange(0.2, 0.9, 0.3)\n",
    "# ratios = np.arange(0.2, 0.9, 0.2)\n",
    "\n",
    "if ADVNET is True and LC is True:\n",
    "    model_fn = lambda: NeuralNet(inception_model, simple_nn_inputs, h21_outputs,\n",
    "                                 model_params=adv_model_params, n=1)\n",
    "    fig, acc = learning_curve(model_fn, integers_fn, ratios=ratios,\n",
    "                              filename=outliers_name(\"adv_nn_learning_curve\"),\n",
    "                              train_params=adv_train_params)\n",
    "    fig\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "K2z4W3aTGyLH"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "cicy3.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": true,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
